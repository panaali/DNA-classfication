# -*- coding: utf-8 -*-
"""dna-classification-vcu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13BLlKCJc5EiKMHP7KEH5hOXyLEIUdX02

# DNA Multi Class Classification
"""


"""## Prepare Google Drive"""

# Run this cell to mount your Google Drive.

local_path = './'

"""## Prepare fastai"""
from fastai import *
from fastai.text import *

"""## Prepare Dataset"""

local_project_path = local_path + 'dna-10class/'

if not os.path.exists(local_project_path):
  os.makedirs(local_project_path)
  
print('local_project_path:', local_project_path)
"""## Create Language Model"""

class dna_tokenizer(BaseTokenizer):
  def tokenizer(slef, t):
    return list(t)

tokenizer = Tokenizer(tok_func=dna_tokenizer, pre_rules=[], post_rules=[], special_cases=[])

# batch size
bs = 64

data_lm = TextLMDataBunch.from_csv(local_project_path, 'combined.csv',
                                   text_cols ='Text', valid_pct= 0.01, tokenizer=tokenizer,
                                   include_bos= False, include_eos=False)

# data_lm.train_ds[0][0].text

# data_lm.train_ds[0][0].data

"""## Create Language Model Learner"""

learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3, pretrained=False).to_fp16()

# learn.lr_find()
# learn.recorder.plot(skip_end = 15)

learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))
learn.save('lm-first')

learn.unfreeze()

learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-1')

learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-2')

learn.fit_one_cycle(10, 1e-4, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-3')

learn.fit_one_cycle(10, 1e-4, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-4')

learn.fit_one_cycle(10, 1e-5, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-5')

learn.fit_one_cycle(10, 1e-5, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-6')

learn.fit_one_cycle(10, 1e-6, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-7')

learn.fit_one_cycle(10, 1e-6, moms=(0.8,0.7))
learn.save('lm-fine-tuned-10-8')


TEXT = "atggcag"
N_WORDS = 40
N_SENTENCES = 2
print("\n".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))

learn.save_encoder('fine_tuned_enc')


print(learn.validate(learn.data.valid_dl))


